From a3b4e9f872c206999006430c6d9e5730db0597ed Mon Sep 17 00:00:00 2001
Message-Id: <a3b4e9f872c206999006430c6d9e5730db0597ed.1473839034.git.xspidera777@gmail.com>
From: AbdulRahm <xspidera777@gmail.com>
Date: Wed, 14 Sep 2016 12:42:31 +0500
Subject: [PATCH] Add 3 more SearchEngines and made FOOL PROFF

For KAF
---
 Hacking scripts/DorkSearcher.py | 156 ++++++++++++++++++++++++++--------------
 1 file changed, 104 insertions(+), 52 deletions(-)

diff --git a/Hacking scripts/DorkSearcher.py b/Hacking scripts/DorkSearcher.py
index cf66094..6997e34 100644
--- a/Hacking scripts/DorkSearcher.py	
+++ b/Hacking scripts/DorkSearcher.py	
@@ -4,7 +4,37 @@ import requests
 import socks
 import socket
 import time
-print("Imported Modules \n NOTE: Google doesnt let you see more searches then a fixed number .")
+print("Imported Modules \n NOTE: There is a fixed number search results you can get from a website.")
+print("========================================================================================================================================")
+print("==Remember Connecting to TOR will make Google ask you Captcha so you will be AutoMatically Shifted To Yahoo and Bing Skipping Google!.==")
+print("========================================================================================================================================\n\n")
+
+
+
+
+
+
+def main():
+    global pages
+    pages = input("How many pages you want to search in each engine (Google,Bing and Yahoo) eg. 5 :   ")
+    pages=int(pages)
+
+    proxy=raw_input("\n Would you like to connect to TOR PROXY \n Y / N \n ")
+    if (proxy.upper()) == "Y":
+        ProxyConnect()
+        global searchG
+        searchG=[]
+        global search
+        search = raw_input("Dork ===> ? \n")
+        print("Converting to string")
+        search = str(search)
+        print ("====YAHOO=====")
+        global printyahoo
+        printyahoo=0
+        searchYahoo()
+    else:
+        printyahoo=1
+        searchGoogle()
 
 def ProxyConnect () :
     try:
@@ -12,82 +42,104 @@ def ProxyConnect () :
         socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS4,"127.0.0.1", 9050, True)
         socket.socket = socks.socksocket
         requests.get("https://www.google.com/")
+        temp = socket.socket
     except:
-        socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, "127.0.0.1", 1080, True)
-        socket.socket = socks.socksocket
+        socket.socket = temp
         print("Could Not Connect to Proxy")
 
-
-
-
-
 def searchGoogle():
+    print ("====GOOGLE====")
     global searchG
     global headers
+    global search
     searchG=[]
-    page=0
+    page=1
     page=str(page)
     search=raw_input("Dork ===> ? \n")
     print("Converting to string")
     search=str(search)
     print("Searching")
-    for i in range (40):
+    for i in range (pages):
         headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}
-        r = requests.get("https://www.google.com/search?sclient=psy-ab&client=windows10&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q="+search+"&start="+page,headers=headers)
+        try:
+            r = requests.get("https://www.google.com/search?client=ubuntu&channel=fs&q="+search+"&ie=utf-8&oe=utf-8&start="+page,headers=headers)
+        except:
+            print("Could not Connect to GOOGLE")
         soup = BeautifulSoup(r.content, "html.parser")
         page=int(page)
         page=page+10
         page=str(page)
-        print (soup.contents)
+        #print (soup.contents)
         for cite in  soup.find_all('cite'):
-            print("")
-            print (cite.text)
-            #searchG.append((cite.text))
-            #print (cite.text)  result__url__domain
-            print("")
-
-
-def searchDuckDuckGo():
-    global searchD
-    searchD=[]
-    search=raw_input("Dork ===> ? \n")
-    print("Converting to string")
-    search=str(search)
+            if (cite.text.find("."))<0:
+                searchYahoo()
+            #print (cite.text)
+            searchG.append((cite.text))
+    searchYahoo()
+
+def searchYahoo():
+    if printyahoo==1:
+        print ("====YAHOO=====")
+
+    global searchY
+    searchY=[]
+    #search=raw_input("Dork ===> ? \n")
+    #print("Converting to string")
+    #search=str(search)
     print("Searching")
+    page=1
+    for i in range(pages):
+        page=str(page)
+        try:
+            r = requests.get("https://search.yahoo.com/search;_ylc=X3oDMTFiN25laTRvBF9TAzIwMjM1MzgwNzUEaXRjAzEEc2VjA3NyY2hfcWEEc2xrA3NyY2h3ZWI-?p="+search+"&fr=yfp-t&fp=1&toggle=1&cop=mss&ei=UTF-8&b="+page)
+            page=int(page)
+            page=page+10
+        except:
+            print("Could Not Connect To the Yahoo")
 
-
-    r = requests.get("https://duckduckgo.com/?q="+search)
-    soup = BeautifulSoup(r.content, "html.parser")
-    for link  in soup.find_all('links'):
-        print("")
-        print (link.text)
-        # searchG.append((cite.text))
-        # print (cite.text)  result__url__domain
-        print("")
+        soup = BeautifulSoup(r.content, "html.parser")
+        #print(soup.prettify())
+        for span  in soup.findAll("span",attrs={'class':" fz-ms fw-m fc-12th wr-bw lh-17"}):
+            if (span.text.find("."))<0:
+                searchBing()
+            #print (span.text)
+            searchY.append((span.text))
+    searchBing()
 
 def searchBing():
+    print ("=====BING=====")
     global searchB
     searchB=[]
-    search=raw_input("Dork ===> ? \n")
+    #search=raw_input("Dork ===> ? \n")
     print("Converting to string")
-    search=str(search)
+    #search=str(search)
     print("Searching")
+    page=1
+    for i in range(pages):
+        page=str(page)
+        try:
+            r = requests.get("http://www.bing.com/search?q="+search+"&qs=n&pq=hello&sc=8-1&sp=-1&sk=&cvid=D0DB7A1DD2F24D0AB7151873430136F6&first="+page+"&FORM=PERE")
+            page=int(page)
+            page=page+10
 
+        except:
+            print("Could Not Connect To the BING")
 
-    r = requests.get("https://duckduckgo.com/?q="+search)
-    soup = BeautifulSoup(r.content, "html.parser")
-    for link  in soup.find_all('links'):
-        print("")
-        print (link.text)
-        # searchG.append((cite.text))
-        # print (cite.text)  result__url__domain
-        print("")
-
-
-
-
-
-#ProxyConnect()
-while 1:
-    #searchGoogle()
-    searchDuckDuckGo()
\ No newline at end of file
+        soup = BeautifulSoup(r.content, "html.parser")
+        #print(soup.prettify())
+        for cite  in soup.findAll("cite"):
+            #print("")
+            #print (cite.text)
+            searchB.append((cite.text))
+    results()
+
+def results():
+    print("\nHere are your Results :) \n")
+    print("Remember the Common results are omitted out")
+    global URLResult
+    URLResult=[]
+    URLResult=list(set().union(searchB,searchY,searchG))
+    for i in URLResult:
+        print (i)
+
+main()
\ No newline at end of file
-- 
2.7.4

